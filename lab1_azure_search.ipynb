{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from approaches.azureretriver import AzureRetrieveApproach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctags_path = './repo/langchain/libs/langchain/tags'\n",
    "ctags_root_path = os.path.dirname(ctags_path)\n",
    "assert os.path.isfile(ctags_path), \"Please run `zsh download_example_rpo.sh` first\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_SEARCH_SERVICE = os.environ[\"AZURE_SEARCH_SERVICE\"]\n",
    "AZURE_SEARCH_TINY_INDEX = os.environ[\"AZURE_SEARCH_TINY_INDEX\"]\n",
    "AZURE_SEARCH_BIGGER_INDEX = os.environ[\"AZURE_SEARCH_BIGGER_INDEX\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tags_file(file_path: str) -> list[dict]:\n",
    "    with open(file_path, 'r', errors='ignore') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    tags = []\n",
    "    for line in lines:\n",
    "        if line.startswith('!'):  # Skip metadata lines\n",
    "            continue\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) >= 4:\n",
    "            tag_name = parts[0]\n",
    "            file_name = parts[1]\n",
    "            pattern = parts[2]\n",
    "            tags.append(dict(tag_name=tag_name, file_name=file_name, pattern=pattern))\n",
    "\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/aicontest/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\") # vector length 384\n",
    "embedding_dimension = embeddings.client.get_sentence_embedding_dimension()\n",
    "\n",
    "def get_embeddings(text: str, normalize=True) -> list:\n",
    "    embeddings.encode_kwargs = {'normalize_embeddings': normalize}\n",
    "    return embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import importlib.util\n",
    "import os\n",
    "\n",
    "def get_source_code(function_name, function_path, ctags_root_path=ctags_root_path):\n",
    "    spec=importlib.util.spec_from_file_location(function_name, os.path.join(ctags_root_path, function_path))\n",
    "    foo = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(foo)\n",
    "    return inspect.getsource(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_code_file_text(metadatas : list[dict]):\n",
    "    code_file_text = \"\"\n",
    "    for i, metadata in enumerate(metadatas):\n",
    "        code_file_text += f'==== File {i+1}/{len(metadata)} ====\\n'\n",
    "        code_file_text += f'File path: {metadata[\"file_name\"]}\\n'\n",
    "        code_file_text += f'Tag name: {metadata[\"tag_name\"]}\\n'\n",
    "        code_string = get_source_code(metadata[\"tag_name\"], metadata[\"file_name\"])\n",
    "        code_file_text += f'Code: {code_string}\\n'\n",
    "        code_file_text += \"\\n\"\n",
    "    return code_file_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a hupful bot that fuilfill the human' program task:\n",
    "\n",
    "The following is releative code:\n",
    "{code_file_text}\n",
    "\n",
    "User: {user_prompt}\n",
    "Ai:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Azure client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_retriever = AzureRetrieveApproach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poc_20231202 created\n"
     ]
    }
   ],
   "source": [
    "azure_retriever.create_index(indedx_name=\"poc_20231202\", embedding_dimension=embedding_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read ctag, embedding and upload to Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tags: 20487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [01:14<00:00, 67.46it/s]\n"
     ]
    }
   ],
   "source": [
    "ctags_root_path = os.path.dirname(ctags_path)\n",
    "tags = read_tags_file(ctags_path)\n",
    "\n",
    "print(f\"Total tags: {len(tags)}\")\n",
    "\n",
    "tags = tags[:5000]\n",
    "\n",
    "documents = []\n",
    "idx = 0\n",
    "for tag in tqdm(tags):\n",
    "    documents.append(\n",
    "        dict(\n",
    "            id=str(idx),\n",
    "            title=tag['file_name'],\n",
    "            metadata=json.dumps(tag),\n",
    "            content=f\"{tag['file_name']} | {tag['tag_name']}\",\n",
    "            category=\"code\",\n",
    "            titleVector=get_embeddings(f\"{tag['file_name']} | {tag['tag_name']}\"),\n",
    "            contentVector=get_embeddings(tag['tag_name'])\n",
    "        )\n",
    "    )\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_retriever.batch_update(documents=documents, index_name=\"poc_20231202\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search using vector similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"How can i add a Custom Prompt Template in this repository? also add the unit-test. Give me an example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = azure_retriever.search(\n",
    "    index_name=\"poc_20231202\", \n",
    "    vector=get_embeddings(text), \n",
    "    fields=\"contentVector\", \n",
    "    top=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: langchain/chains/query_constructor/prompt.py\n",
      "Score: 0.7941357\n",
      "Metadata: {\"tag_name\": \"EXAMPLE_PROMPT_TEMPLATE\", \"file_name\": \"langchain/chains/query_constructor/prompt.py\", \"pattern\": \"/^EXAMPLE_PROMPT_TEMPLATE = \\\"\\\"\\\"\\\\\\\\$/;\\\"\"}\n",
      "Content: langchain/chains/query_constructor/prompt.py | EXAMPLE_PROMPT_TEMPLATE\n",
      "Category: code\n",
      "\n",
      "Title: langchain/chains/natbot/prompt.py\n",
      "Score: 0.7826364\n",
      "Metadata: {\"tag_name\": \"_PROMPT_TEMPLATE\", \"file_name\": \"langchain/chains/natbot/prompt.py\", \"pattern\": \"/^_PROMPT_TEMPLATE = \\\"\\\"\\\"$/;\\\"\"}\n",
      "Content: langchain/chains/natbot/prompt.py | _PROMPT_TEMPLATE\n",
      "Category: code\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Metadata: {result['metadata']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/aicontest/lib/python3.11/site-packages/langchain/chat_models/azure_openai.py:155: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://f19855e6-c488-4c48-a0f0-e7bb2b9527fa-canadaeast.openai.azure.com to https://f19855e6-c488-4c48-a0f0-e7bb2b9527fa-canadaeast.openai.azure.com/openai.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/aicontest/lib/python3.11/site-packages/langchain/chat_models/azure_openai.py:162: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/aicontest/lib/python3.11/site-packages/langchain/chat_models/azure_openai.py:170: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://f19855e6-c488-4c48-a0f0-e7bb2b9527fa-canadaeast.openai.azure.com to https://f19855e6-c488-4c48-a0f0-e7bb2b9527fa-canadaeast.openai.azure.com/openai.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=os.environ.get(\"DEPLOYMENT_NAME\"),\n",
    "    temperature=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(user_prompt: str) -> str:\n",
    "    # find docs similar to user_prompt\n",
    "    results = azure_retriever.search(\n",
    "        index_name=\"poc_20231202\", \n",
    "        vector=get_embeddings(user_prompt), \n",
    "        fields=\"contentVector\", \n",
    "        top=10\n",
    "    )\n",
    "    metadatas = []\n",
    "    for result in results:\n",
    "        result_dict = json.loads(result['metadata'])\n",
    "        if result_dict['file_name'].endswith(\".py\"):\n",
    "            metadatas.append(result_dict)\n",
    "    metadatas = metadatas[:3]\n",
    "\n",
    "    user_prompt = template.format(code_file_text=create_code_file_text(metadatas), user_prompt=user_prompt)\n",
    "    \n",
    "    # call openai api here\n",
    "    message = HumanMessage(content=user_prompt)\n",
    "    return llm([message]).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "üë©‚Äçüíª : What is Langchain design for?\n",
      "====================\n",
      "ü§ñ : Langchain is designed as a language generation framework that allows users to build and customize language models for various tasks. It provides a flexible and modular architecture that enables the creation of chains, which are sequences of steps that process input data and generate output. The framework includes components such as transformers, retrievers, and callbacks that can be combined to create complex language models. The design of Langchain aims to provide a user-friendly and extensible platform for developing and deploying language models for tasks such as text generation, translation, summarization, and more.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"What is Langchain design for?\"\n",
    "result = ask(user_question)\n",
    "\n",
    "print(\"=\"*20)\n",
    "print(f\"üë©‚Äçüíª : {user_question}\")\n",
    "print(\"=\"*20)\n",
    "print(f\"ü§ñ : {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "üë©‚Äçüíª : How can i add a Custom Prompt Template in this repository? also add the unit-test. Give me an example\n",
      "====================\n",
      "ü§ñ : To add a custom prompt template to this repository, you can follow these steps:\n",
      "\n",
      "1. Create a new Python file in the appropriate directory for the chain you are working on (e.g., `langchain/chains/query_constructor/prompt.py`).\n",
      "2. Define your custom prompt template as a string using the desired format and placeholders. For example:\n",
      "\n",
      "```python\n",
      "_PROMPT_TEMPLATE = \"\"\"\n",
      "Your custom prompt template goes here.\n",
      "You can use placeholders like {placeholder} to dynamically insert values.\n",
      "\"\"\"\n",
      "\n",
      "PROMPT = PromptTemplate(\n",
      "    input_variables=[\"placeholder\"],  # List the input variables used in the template\n",
      "    template=_PROMPT_TEMPLATE,\n",
      ")\n",
      "```\n",
      "\n",
      "3. Save the file and commit it to the repository.\n",
      "\n",
      "To add a unit test for your custom prompt template, you can create a new Python file in the `tests` directory following the naming convention `test_prompt_template.py`. In this file, you can write test cases to verify the functionality of your prompt template. Here's an example:\n",
      "\n",
      "```python\n",
      "import unittest\n",
      "from langchain.chains.query_constructor.prompt import PROMPT\n",
      "\n",
      "class TestPromptTemplate(unittest.TestCase):\n",
      "    def test_prompt_template(self):\n",
      "        # Test case 1\n",
      "        input_values = {\n",
      "            \"placeholder\": \"value1\",\n",
      "        }\n",
      "        expected_output = \"Expected output for test case 1\"\n",
      "        self.assertEqual(PROMPT.render(**input_values), expected_output)\n",
      "\n",
      "        # Test case 2\n",
      "        input_values = {\n",
      "            \"placeholder\": \"value2\",\n",
      "        }\n",
      "        expected_output = \"Expected output for test case 2\"\n",
      "        self.assertEqual(PROMPT.render(**input_values), expected_output)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    unittest.main()\n",
      "```\n",
      "\n",
      "Make sure to replace `\"value1\"`, `\"value2\"`, and the expected output strings with the actual values and expected outputs for your specific prompt template.\n",
      "\n",
      "Save the file and run the unit test using a test runner (e.g., `python -m unittest tests.test_prompt_template`) to verify that your prompt template is working correctly.\n",
      "\n",
      "Remember to commit the test file along with your prompt template file.\n",
      "\n",
      "I hope this helps! Let me know if you have any further questions.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"How can i add a Custom Prompt Template in this repository? also add the unit-test. Give me an example\"\n",
    "result = ask(user_question)\n",
    "\n",
    "print(\"=\"*20)\n",
    "print(f\"üë©‚Äçüíª : {user_question}\")\n",
    "print(\"=\"*20)\n",
    "print(f\"ü§ñ : {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicontest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
