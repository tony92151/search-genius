{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.embeddings import (\n",
    "    HuggingFaceEmbeddings,\n",
    "    OpenAIEmbeddings,\n",
    "    HuggingFaceInstructEmbeddings,\n",
    ")\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from approaches.azureretriver import AzureRetrieveApproach\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "AZURE_SEARCH_SERVICE = os.environ[\"AZURE_SEARCH_SERVICE\"]\n",
    "AZURE_SEARCH_TINY_INDEX = os.environ[\"AZURE_SEARCH_TINY_INDEX\"]\n",
    "AZURE_SEARCH_BIGGER_INDEX = os.environ[\"AZURE_SEARCH_BIGGER_INDEX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import importlib.util\n",
    "import os\n",
    "\n",
    "\n",
    "def read_tags_file(file_path: str) -> list[dict]:\n",
    "    with open(file_path, \"r\", errors=\"ignore\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    tags = []\n",
    "    for line in lines:\n",
    "        if line.startswith(\"!\"):  # Skip metadata lines\n",
    "            continue\n",
    "        parts = line.split(\"\\t\")\n",
    "        if len(parts) >= 4:\n",
    "            tag_name = parts[0]\n",
    "            file_name = parts[1]\n",
    "            pattern = parts[2]\n",
    "            tags.append(dict(tag_name=tag_name, file_name=file_name, pattern=pattern))\n",
    "\n",
    "    return tags\n",
    "\n",
    "\n",
    "def get_embeddings(text: str, normalize=True) -> list:\n",
    "    embeddings.encode_kwargs = {\"normalize_embeddings\": normalize}\n",
    "    return embeddings.embed_query(text)\n",
    "\n",
    "\n",
    "def get_source_code(function_name, function_path, ctags_root_path):\n",
    "    spec = importlib.util.spec_from_file_location(\n",
    "        function_name, os.path.join(ctags_root_path, function_path)\n",
    "    )\n",
    "    foo = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(foo)\n",
    "    return inspect.getsource(foo)\n",
    "\n",
    "\n",
    "def create_code_file_text(metadatas: list[dict]):\n",
    "    code_file_text = \"\"\n",
    "    for i, metadata in enumerate(metadatas):\n",
    "        code_file_text += f\"==== File {i+1}/{len(metadata)} ====\\n\"\n",
    "        code_file_text += f'File path: {metadata[\"file_name\"]}\\n'\n",
    "        code_file_text += f'Tag name: {metadata[\"tag_name\"]}\\n'\n",
    "        code_string = metadata.get(\"code\")\n",
    "        code_file_text += f\"Code: {code_string}\\n\"\n",
    "        code_file_text += \"\\n\"\n",
    "    return code_file_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a hupful bot that fuilfill the human' program task:\n",
    "\n",
    "The following is releative code:\n",
    "{code_file_text}\n",
    "\n",
    "User: {user_prompt}\n",
    "Ai:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")  # vector length 384\n",
    "embedding_dimension = embeddings.client.get_sentence_embedding_dimension()\n",
    "\n",
    "ctags_path = \"./repo/aladdin/tags\"\n",
    "ctags_root_path = os.path.dirname(ctags_path)\n",
    "assert os.path.isfile(ctags_path), \"Please run `zsh download_example_rpo.sh` first\"\n",
    "\n",
    "azure_retriever = AzureRetrieveApproach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "class TagFinder(ast.NodeVisitor):\n",
    "    def __init__(self, source_code: str, tag_name: str):\n",
    "        self.source_code = source_code\n",
    "        self.tag_name = tag_name\n",
    "        self.found_code = None\n",
    "\n",
    "    def visit_Assign(self, node: ast.Assign) -> None:\n",
    "        for target in node.targets:\n",
    "            if isinstance(target, ast.Name) and target.id == self.tag_name:\n",
    "                self.found_code = ast.get_source_segment(self.source_code, node)\n",
    "\n",
    "\n",
    "def find_tag_in_source(file_path: str, tag_name: str) -> str:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        source_code = file.read()\n",
    "\n",
    "    finder = TagFinder(source_code, tag_name)\n",
    "    finder.visit(ast.parse(source_code))\n",
    "\n",
    "    return finder.found_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import tokenize\n",
    "from io import BytesIO\n",
    "from typing import List, Dict, Union, Optional, Any, Type, Callable\n",
    "from typing_extensions import TypedDict\n",
    "from rich import print\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Iterator, List\n",
    "\n",
    "\n",
    "def list_all_files(directory: str) -> Iterator[Path]:\n",
    "    \"\"\"Yield all files from the given directory.\"\"\"\n",
    "    return Path(directory).rglob(\"*\")\n",
    "\n",
    "\n",
    "def filter_files_by_type(\n",
    "    files: Iterator[Path], file_types: Iterable[str]\n",
    ") -> Iterable[Path]:\n",
    "    \"\"\"Filter files by the given file types.\"\"\"\n",
    "    return (file for file in files if file.suffix in file_types)\n",
    "\n",
    "\n",
    "def get_file_paths(directory: str, file_types: List[str]) -> List[Path]:\n",
    "    \"\"\"Get file paths from the specified directory, filtered by the provided file types.\"\"\"\n",
    "    return list(filter_files_by_type(list_all_files(directory), file_types))\n",
    "\n",
    "\n",
    "class DependencyData(TypedDict):\n",
    "    modules: List[str]\n",
    "    functions_called: List[str]\n",
    "    global_vars: List[str]\n",
    "    classes_used: List[str]\n",
    "    function_codes: Dict[str, str]\n",
    "    class_codes: Dict[str, str]\n",
    "\n",
    "\n",
    "def extract_from_node(extractor: Type, node: ast.AST) -> List[str]:\n",
    "    return extractor.extract(node)\n",
    "\n",
    "\n",
    "class ImportExtractor:\n",
    "    @staticmethod\n",
    "    def extract(node: ast.AST) -> List[str]:\n",
    "        if isinstance(node, ast.Import):\n",
    "            return [n.name for n in node.names]\n",
    "        elif isinstance(node, ast.ImportFrom):\n",
    "            return [f\"{node.module}.{n.name}\" for n in node.names]\n",
    "        return []\n",
    "\n",
    "\n",
    "class FunctionCallExtractor:\n",
    "    @staticmethod\n",
    "    def extract(node: ast.AST) -> List[str]:\n",
    "        if isinstance(node, ast.Call):\n",
    "            if isinstance(node.func, ast.Name):\n",
    "                return [node.func.id]\n",
    "            elif isinstance(node.func, ast.Attribute):\n",
    "                return [node.func.attr]\n",
    "        return []\n",
    "\n",
    "\n",
    "class GlobalVarExtractor:\n",
    "    @staticmethod\n",
    "    def extract(node: ast.AST) -> List[str]:\n",
    "        return node.names if isinstance(node, ast.Global) else []\n",
    "\n",
    "\n",
    "class ClassUsageExtractor:\n",
    "    @staticmethod\n",
    "    def extract(node: ast.AST) -> List[str]:\n",
    "        return [node.name] if isinstance(node, ast.ClassDef) else []\n",
    "\n",
    "\n",
    "def extract_code_segment(\n",
    "    code: str, node: Union[ast.FunctionDef, ast.ClassDef]\n",
    ") -> Optional[str]:\n",
    "    # Use the line numbers provided by the ast node\n",
    "    start_line = node.lineno - 1  # AST line numbers are 1-based, lists are 0-based\n",
    "    end_line = node.end_lineno if hasattr(node, \"end_lineno\") else start_line\n",
    "    return \"\\n\".join(code.splitlines()[start_line : end_line + 1])\n",
    "\n",
    "\n",
    "def analyze_code(code: str) -> DependencyData:\n",
    "    tree = ast.parse(code)\n",
    "\n",
    "    data: DependencyData = {\n",
    "        \"modules\": [],\n",
    "        \"functions_called\": [],\n",
    "        \"global_vars\": [],\n",
    "        \"classes_used\": [],\n",
    "        \"function_codes\": {},\n",
    "        \"class_codes\": {},\n",
    "    }\n",
    "\n",
    "    extractors = {\n",
    "        \"modules\": ImportExtractor,\n",
    "        \"functions_called\": FunctionCallExtractor,\n",
    "        \"global_vars\": GlobalVarExtractor,\n",
    "        \"classes_used\": ClassUsageExtractor,\n",
    "    }\n",
    "\n",
    "    for key, extractor in extractors.items():\n",
    "        for node in ast.walk(tree):\n",
    "            data[key].extend(extract_from_node(extractor, node))\n",
    "\n",
    "    for node in tree.body:  # Only top-level nodes\n",
    "        if isinstance(node, ast.FunctionDef) and not node.name.startswith(\"_\"):\n",
    "            data[\"function_codes\"][node.name] = extract_code_segment(code, node)\n",
    "        elif isinstance(node, ast.ClassDef):\n",
    "            data[\"class_codes\"][node.name] = extract_code_segment(code, node)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=os.environ.get(\"DEPLOYMENT_NAME\"),\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "SUMMARY_TEMPLATE = \"\"\"\\\n",
    "Please summary the following code in 50 tokens:\n",
    "```\n",
    "{code}\n",
    "```\n",
    "\n",
    "summary:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def summary_code(llm: AzureChatOpenAI, code: str) -> str:\n",
    "    if not code:\n",
    "        return \"\"\n",
    "    message = HumanMessage(content=SUMMARY_TEMPLATE.format(code=code))\n",
    "    return llm([message]).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poc_aladdin-2023-12-03 created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total tags: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1990</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total tags: \u001b[1;36m1990\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1990 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m             tag[\u001b[39m'\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m# if tag['tag_kind'] == 'f' or tag['tag_kind'] == 'c':\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m#     code = tag.get('code')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m#     tag['summary'] = summary_code(code)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m# else:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m#     tag['summary'] = ''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m documents\u001b[39m.\u001b[39mappend(\u001b[39mdict\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m         \u001b[39mid\u001b[39m\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(idx),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m         title\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtag[\u001b[39m'\u001b[39m\u001b[39mfile_name\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m{\u001b[39;00mtag[\u001b[39m'\u001b[39m\u001b[39mtag_name\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m         metadata\u001b[39m=\u001b[39mjson\u001b[39m.\u001b[39mdumps(tag),\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m         content\u001b[39m=\u001b[39mtag[\u001b[39m'\u001b[39;49m\u001b[39msummary\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m         category\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m         titleVector\u001b[39m=\u001b[39mget_embeddings(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtag[\u001b[39m'\u001b[39m\u001b[39mfile_name\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m{\u001b[39;00mtag[\u001b[39m'\u001b[39m\u001b[39mtag_name\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m         contentVector\u001b[39m=\u001b[39mget_embeddings(tag[\u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     ))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m idx\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'summary'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "from utils.tagreader import read_tags_file\n",
    "\n",
    "azure_retriever.create_index(\n",
    "    indedx_name=\"poc_aladdin-2023-12-03\", embedding_dimension=embedding_dimension\n",
    ")\n",
    "\n",
    "ctags_root_path = os.path.dirname(ctags_path)\n",
    "tags = read_tags_file(ctags_path, [\".py\"])\n",
    "\n",
    "print(f\"Total tags: {len(tags)}\")\n",
    "\n",
    "# tags = tags[:10]\n",
    "\n",
    "documents = []\n",
    "idx = 0\n",
    "for tag in tqdm(tags):\n",
    "    if tag[\"file_name\"].endswith(\".py\"):\n",
    "        file_path = os.path.normpath(os.path.join(ctags_root_path, tag[\"file_name\"]))\n",
    "        with open(file_path, \"r\") as source:\n",
    "            code = source.read()\n",
    "        data = analyze_code(code)\n",
    "\n",
    "        for name, val in data[\"class_codes\"].items():\n",
    "            if tag[\"tag_name\"] in val:\n",
    "                tag[\"code\"] = val\n",
    "            else:\n",
    "                tag[\"code\"] = \"\"\n",
    "\n",
    "        # if tag['tag_kind'] == 'f' or tag['tag_kind'] == 'c':\n",
    "        #     code = tag.get('code')\n",
    "        #     tag['summary'] = summary_code(code)\n",
    "        # else:\n",
    "        #     tag['summary'] = ''\n",
    "\n",
    "    documents.append(\n",
    "        dict(\n",
    "            id=str(idx),\n",
    "            title=f\"{tag['file_name']} | {tag['tag_name']}\",\n",
    "            metadata=json.dumps(tag),\n",
    "            content=tag[\"summary\"],\n",
    "            category=\"code\",\n",
    "            titleVector=get_embeddings(f\"{tag['file_name']} | {tag['tag_name']}\"),\n",
    "            contentVector=get_embeddings(tag[\"summary\"]),\n",
    "        )\n",
    "    )\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poc_aladdin-2023-12-03 created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total tags: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1990</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total tags: \u001b[1;36m1990\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1990 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)\n",
      "\u001b[1;32m/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m             tag[\u001b[39m'\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m# if tag['tag_kind'] == 'f' or tag['tag_kind'] == 'c':\u001b[39;00m\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m#     code = tag.get('code')\u001b[39;00m\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m#     tag['summary'] = summary_code(code)\u001b[39;00m\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m# else:\u001b[39;00m\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m#     tag['summary'] = ''\u001b[39;00m\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m documents\u001b[39m.\u001b[39mappend(\u001b[39mdict\u001b[39m(\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m         \u001b[39mid\u001b[39m\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(idx),\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m         title\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtag[\u001b[39m'\u001b[39m\u001b[39mfile_name\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m{\u001b[39;00mtag[\u001b[39m'\u001b[39m\u001b[39mtag_name\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m         metadata\u001b[39m=\u001b[39mjson\u001b[39m.\u001b[39mdumps(tag),\n",
      "\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m         content\u001b[39m=\u001b[39mtag[\u001b[39m'\u001b[39;49m\u001b[39msummary\u001b[39;49m\u001b[39m'\u001b[39;49m],\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m         category\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m\"\u001b[39m,\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m         titleVector\u001b[39m=\u001b[39mget_embeddings(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtag[\u001b[39m'\u001b[39m\u001b[39mfile_name\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m{\u001b[39;00mtag[\u001b[39m'\u001b[39m\u001b[39mtag_name\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m),\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m         contentVector\u001b[39m=\u001b[39mget_embeddings(tag[\u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m]),\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     ))\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rkyer_chang/dev/search-genius/poc_aladdin.ipynb#X10sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m idx\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "\n",
      "\u001b[0;31mKeyError\u001b[0m: 'summary'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "from utils.tagreader import read_tags_file\n",
    "\n",
    "azure_retriever.create_index(\n",
    "    indedx_name=\"poc_aladdin-2023-12-03\", embedding_dimension=embedding_dimension\n",
    ")\n",
    "\n",
    "ctags_root_path = os.path.dirname(ctags_path)\n",
    "tags = read_tags_file(ctags_path, [\".py\"])\n",
    "\n",
    "print(f\"Total tags: {len(tags)}\")\n",
    "\n",
    "# tags = tags[:10]\n",
    "\n",
    "documents = []\n",
    "idx = 0\n",
    "for tag in tqdm(tags):\n",
    "    if tag[\"file_name\"].endswith(\".py\"):\n",
    "        file_path = os.path.normpath(os.path.join(ctags_root_path, tag[\"file_name\"]))\n",
    "        with open(file_path, \"r\") as source:\n",
    "            code = source.read()\n",
    "        data = analyze_code(code)\n",
    "\n",
    "        for name, val in data[\"class_codes\"].items():\n",
    "            if tag[\"tag_name\"] in val:\n",
    "                tag[\"code\"] = val\n",
    "            else:\n",
    "                tag[\"code\"] = \"\"\n",
    "\n",
    "        # if tag['tag_kind'] == 'f' or tag['tag_kind'] == 'c':\n",
    "        #     code = tag.get('code')\n",
    "        #     tag['summary'] = summary_code(code)\n",
    "        # else:\n",
    "        #     tag['summary'] = ''\n",
    "\n",
    "    documents.append(\n",
    "        dict(\n",
    "            id=str(idx),\n",
    "            title=f\"{tag['file_name']} | {tag['tag_name']}\",\n",
    "            metadata=json.dumps(tag),\n",
    "            content=tag[\"summary\"],\n",
    "            category=\"code\",\n",
    "            titleVector=get_embeddings(f\"{tag['file_name']} | {tag['tag_name']}\"),\n",
    "            contentVector=get_embeddings(tag[\"summary\"]),\n",
    "        )\n",
    "    )\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_retriever.create_index(\n",
    "    indedx_name=\"poc_aladdin-2023-12-03\", embedding_dimension=embedding_dimension\n",
    ")\n",
    "azure_retriever.batch_update(documents=documents, index_name=\"poc_aladdin-2023-12-03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"How Do I moidfy search app pattern?\"\n",
    "results = azure_retriever.search(\n",
    "    index_name=\"poc_aladdin-2023-12-03\",\n",
    "    vector=get_embeddings(text),\n",
    "    fields=\"contentVector\",\n",
    "    top=10,\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Metadata: {result['metadata']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"How Do I moidfy regex of searchapp_explainer routing pattern?\"\n",
    "results = azure_retriever.search(\n",
    "    index_name=\"poc_aladdin-2023-12-03\",\n",
    "    vector=get_embeddings(text),\n",
    "    fields=\"contentVector\",\n",
    "    top=10,\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Metadata: {result['metadata']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "def ask(user_prompt: str) -> str:\n",
    "    # find docs similar to user_prompt\n",
    "    results = azure_retriever.hybrid_reranking_search(\n",
    "        index_name=\"poc_aladdin-2023-12-03\",\n",
    "        text=user_prompt,\n",
    "        vector=get_embeddings(user_prompt),\n",
    "        fields=\"contentVector\",\n",
    "        top=5,\n",
    "    )\n",
    "\n",
    "    for result in results:\n",
    "        print(f\"Title: {result['title']}\")\n",
    "        # print(f\"Score: {result['@search.score']}\")\n",
    "        print(f\"Metadata: {result['metadata']}\")\n",
    "        # print(f\"Content: {result['content']}\")\n",
    "        # print(f\"Category: {result['category']}\\n\")\n",
    "    metadatas = []\n",
    "    for result in results:\n",
    "        result_dict = json.loads(result[\"metadata\"])\n",
    "        # if result_dict['file_name'].endswith(\".py\"):\n",
    "        metadatas.append(result_dict)\n",
    "    # metadatas = metadatas[:2]\n",
    "\n",
    "    # TODO: Should handle token length limit here\n",
    "    print(f\"{metadatas = }\")\n",
    "    user_prompt = template.format(\n",
    "        code_file_text=create_code_file_text(metadatas), user_prompt=user_prompt\n",
    "    )\n",
    "    print(f\"üí¨ {user_prompt = }\")\n",
    "\n",
    "    # call openai api here\n",
    "    message = HumanMessage(content=user_prompt)\n",
    "    return llm([message]).content\n",
    "\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=os.environ.get(\"DEPLOYMENT_NAME\"),\n",
    "    temperature=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"How to add new plugin for companion?\"\n",
    "result = ask(user_question)\n",
    "\n",
    "print(\"=\" * 20)\n",
    "print(f\"üë©‚Äçüíª : {user_question}\")\n",
    "print(\"=\" * 20)\n",
    "print(f\"ü§ñ : {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"How to modify event bus?\"\n",
    "result = ask(user_question)\n",
    "\n",
    "print(\"=\" * 20)\n",
    "print(f\"üë©‚Äçüíª : {user_question}\")\n",
    "print(\"=\" * 20)\n",
    "print(f\"ü§ñ : {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"How to add fake case for SEARCH_APP_PROMPTS\"\n",
    "result = ask(user_question)\n",
    "\n",
    "print(\"=\" * 20)\n",
    "print(f\"üë©‚Äçüíª : {user_question}\")\n",
    "print(\"=\" * 20)\n",
    "print(f\"ü§ñ : {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
